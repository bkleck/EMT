{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pipeline_inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hMiArvZlE4_",
        "outputId": "f09b59f8-dc5d-4737-dcba-670c368a69d8"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AtdLZbvlR3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3562d02-62bf-420a-ee62-10b92897e6cc"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/custom-EM-BERT/prof_entity/lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/custom-EM-BERT/prof_entity/lightning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECQAgHJSllB5",
        "outputId": "14c16162-8dd1-43ef-d170-4764eee71605"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu May 27 04:45:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_RWP26qlsqs"
      },
      "source": [
        "# Set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4EylNNVluPL",
        "outputId": "8e49e64a-17f4-4cfa-91ce-60628273aa10"
      },
      "source": [
        "pip install jsonlines datasets pytorch_lightning transformers lightning_transformers ipython-autotime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.6.2)\n",
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.7/dist-packages (1.3.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: lightning_transformers in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.9)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchmetrics>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.3.2)\n",
            "Requirement already satisfied: PyYAML<=5.4.1,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (5.4.1)\n",
            "Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.3.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.18.2)\n",
            "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.4.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: fairscale in /usr/local/lib/python3.7/dist-packages (from lightning_transformers) (0.3.7)\n",
            "Requirement already satisfied: hydra-core>=1.1.0.dev4 in /usr/local/lib/python3.7/dist-packages (from lightning_transformers) (1.1.0rc1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from lightning_transformers) (0.1.95)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (from lightning_transformers) (0.0.4)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (56.1.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.34.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.12.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.30.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1.0.dev4->lightning_transformers) (5.1.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1.0.dev4->lightning_transformers) (4.8)\n",
            "Requirement already satisfied: omegaconf==2.1.0.rc1 in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1.0.dev4->lightning_transformers) (2.1.0rc1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score->lightning_transformers) (3.2.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.0.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.2.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN_opCyOl0NY"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import jsonlines\n",
        "from typing import Any, Dict, List, Optional\n",
        "from datasets import Dataset, load_dataset, DatasetDict\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import BackboneFinetuning, BaseFinetuning\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from pytorch_lightning.callbacks import ModelPruning, EarlyStopping, ModelCheckpoint\n",
        "from lightning_transformers.core.nlp import HFBackboneConfig, HFTransformerDataConfig, HFDataModule\n",
        "from lightning_transformers.task.nlp.text_classification import (\n",
        "    TextClassificationDataModule, TextClassificationTransformer)\n",
        "from transformers import AutoTokenizer, PreTrainedTokenizerBase, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz8Fi2Zfl2V0"
      },
      "source": [
        "# Lightning Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71OzJNRWl1sh"
      },
      "source": [
        "class EntityMatchingDataModule(TextClassificationDataModule):\n",
        "    def __init__(self,\n",
        "                 cfg: HFTransformerDataConfig,\n",
        "                 tokenizer: PreTrainedTokenizerBase,\n",
        "                 train_data: pd.DataFrame,\n",
        "                 val_data: pd.DataFrame,\n",
        "                 test_data: pd.DataFrame):\n",
        "        super().__init__(tokenizer, cfg)\n",
        "        self.train_data = train_data\n",
        "        self.val_data = val_data\n",
        "        self.test_data = test_data\n",
        "\n",
        "    def load_dataset(self) -> DatasetDict:\n",
        "        return DatasetDict({\n",
        "            'train': Dataset.from_pandas(train_data),\n",
        "            'validation': Dataset.from_pandas(val_data),\n",
        "            'test': Dataset.from_pandas(test_data)})\n",
        "\n",
        "    def process_data(self, dataset, stage: Optional[str] = None) -> Dataset:\n",
        "        dataset = EntityMatchingDataModule.preprocess(\n",
        "            dataset,\n",
        "            tokenizer=self.tokenizer,\n",
        "            padding=self.cfg.padding,\n",
        "            truncation=self.cfg.truncation,\n",
        "            max_length=self.cfg.max_length,\n",
        "        )\n",
        "        cols_to_keep = [\n",
        "            x for x in [\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"] if x in dataset[\"train\"].features\n",
        "        ]\n",
        "        dataset.set_format(\"torch\", columns=cols_to_keep)\n",
        "        self.labels = dataset[\"train\"].features[\"labels\"]\n",
        "        self.labels.num_classes = len(dataset['train']['labels'].unique())\n",
        "        return dataset\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_to_features(\n",
        "        example_batch: Any, _, tokenizer: PreTrainedTokenizerBase, **tokenizer_kwargs\n",
        "    ):\n",
        "        return tokenizer(example_batch['descA'],\n",
        "                         example_batch['descB'],\n",
        "                         padding=True,\n",
        "                         truncation=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess(ds: Dataset, **fn_kwargs) -> Dataset:\n",
        "        ds = ds.map(\n",
        "            # todo: change this to self.convert_to_features for users to override\n",
        "            EntityMatchingDataModule.convert_to_features,\n",
        "            batched=True,\n",
        "            with_indices=True,\n",
        "            fn_kwargs=fn_kwargs,\n",
        "        )\n",
        "        ds.rename_column_(\"label\", \"labels\")\n",
        "        return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aQ4ix3wl8xd"
      },
      "source": [
        "class EntityMatcher(TextClassificationTransformer):\n",
        "    def __init__(self, learning_rate=1e-5, max_lr=1e-3,\n",
        "                 *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        # this is to initialize the backbone in this instance\n",
        "        for k,v in kwargs.items():\n",
        "            if k == 'backbone': \n",
        "                self.backbone = v\n",
        "\n",
        "        self.lr = learning_rate\n",
        "        self.max_lr = max_lr\n",
        "    \n",
        "    def forward(self, x): # for inference\n",
        "        # import pdb; pdb.set_trace()\n",
        "        input_ids = x['input_ids']\n",
        "        token_type_ids = x['token_type_ids']\n",
        "        attention_mask = x['attention_mask']\n",
        "        return self.model(\n",
        "            input_ids=input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "    def predict_step(self, batch, batch_idx: int, dataloader_idx: int = None):\n",
        "        return self(batch)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(self.parameters(), lr=1e-5)\n",
        "\n",
        "        # cyclic learning rate finder\n",
        "        # optimizer = torch.optim.AdamW(self.parameters())\n",
        "        # return {\n",
        "        #     'optimizer': optimizer,\n",
        "        #     # cyclic LR not really necessary in this use-case, base LR is better\n",
        "        #     'lr_scheduler': {\n",
        "        #         'scheduler': torch.optim.lr_scheduler.CyclicLR(\n",
        "        #             optimizer,\n",
        "        #             base_lr=self.lr,\n",
        "        #             max_lr=self.max_lr,\n",
        "        #             mode='triangular',\n",
        "        #             cycle_momentum=False),\n",
        "        #         'interval': 'step',\n",
        "        #         'frequency': 500,\n",
        "        #         'monitor': 'val_loss'\n",
        "        #     }\n",
        "        # }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya3ZivLpmGdr"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7VoYbJ3mLfy",
        "outputId": "a8a417fa-2e4e-4779-ffc0-02f0a00b69f9"
      },
      "source": [
        "%load_ext autotime\n",
        "# display time for each cell execution"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 62 µs (started: 2021-05-27 04:45:32 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb1LSYqyhXl_",
        "outputId": "a2c0f0f9-4b83-4179-d4bc-b224dc65ce64"
      },
      "source": [
        "test_data = pd.read_csv('data/test.csv')\n",
        "\n",
        "test_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(764, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "stream",
          "text": [
            "time: 32.6 ms (started: 2021-05-27 04:45:32 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiXD6grrhfYd",
        "outputId": "58aa0615-440f-42c7-d265-f182beb73c0c"
      },
      "source": [
        "# data_loader = EntityMatchingDataModule(\n",
        "#     cfg=HFTransformerDataConfig(\n",
        "#         # num_workers=12,\n",
        "#         batch_size=8, # keep to max of 8, only use 16 with colab pro\n",
        "#         max_length=512),\n",
        "#     tokenizer=tokenizer,\n",
        "#     train_data=train_data,\n",
        "#     val_data=val_data,\n",
        "#     test_data= test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.05 ms (started: 2021-05-27 04:45:32 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1AYidJRh6OQ",
        "outputId": "5fd4e776-0396-4f7e-8c6a-be3b09ef6e02"
      },
      "source": [
        "model = EntityMatcher.load_from_checkpoint(checkpoint_path = 'bert_final.ckpt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time: 50.2 s (started: 2021-05-27 04:45:32 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GNctRnX9vQJ",
        "outputId": "bbcc2787-1dd0-416a-efd5-d4d8422e5e11"
      },
      "source": [
        "# call the pipeline from the model -- for inference\n",
        "# https://huggingface.co/transformers/main_classes/pipelines.html#transformers.TextClassificationPipeline\n",
        "\n",
        "pipeline = model.hf_pipeline\n",
        "model.hf_pipeline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.pipelines.text_classification.TextClassificationPipeline at 0x7fb6f2bdb3d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "stream",
          "text": [
            "time: 5.29 ms (started: 2021-05-27 04:46:22 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22ly71oJiW5z",
        "outputId": "2c1f55a3-28bd-464a-fb63-4a3ed940ebce"
      },
      "source": [
        "# # call setup to initiate data loader without training step -- for inference\n",
        "# data_loader.setup()\n",
        "\n",
        "# test_loader = data_loader.test_dataloader()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.28 ms (started: 2021-05-27 04:46:22 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccqfRb6SGmau",
        "outputId": "4123855e-1015-4794-9b71-3c1168ab76fc"
      },
      "source": [
        "text_list = []\n",
        "\n",
        "for index,row in test_data.iterrows():\n",
        "  A = row['descA']\n",
        "  B = row['descB']\n",
        "  text = A + B\n",
        "  # if len(text) > 512:\n",
        "  #   text = text[0:512]\n",
        "  text_list.append(text)\n",
        "\n",
        "print(len(text_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "764\n",
            "time: 69.4 ms (started: 2021-05-27 04:46:22 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN0A4Q2WJChu",
        "outputId": "b546326f-7283-47f0-bdc1-8f511c63b3f5"
      },
      "source": [
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "dataloader = list(chunks(text_list, 8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 8.78 ms (started: 2021-05-27 04:48:52 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0enj-6syJli2",
        "outputId": "245dadc9-a56c-46e6-eb4e-1d0fb82ab0b1"
      },
      "source": [
        "print(len(dataloader[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "time: 1.08 ms (started: 2021-05-27 04:49:16 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KvsLANninzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb19fd6-de0d-49b8-a73a-87521fc827c7"
      },
      "source": [
        "# https://huggingface.co/transformers/task_summary.html#sequence-classification\n",
        "pred_list = []\n",
        "for batch in dataloader:\n",
        "  predicted_values = pipeline(batch, tokenizer='bert-base-uncased', model='bert-base-uncased', truncation=True, padding=True)\n",
        "  pred_list = pred_list + predicted_values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 3min 42s (started: 2021-05-27 04:50:59 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzLWD7AmtzJN",
        "outputId": "94885732-ce3b-4a4e-e098-668e4e929ca3"
      },
      "source": [
        "labels = []\n",
        "for i in pred_list:\n",
        "  labels.append(i['label'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.91 ms (started: 2021-05-27 04:57:22 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "i858GjJkq9C0",
        "outputId": "99ffc34b-bb9d-4e9c-c750-0a08fc1ed8ec"
      },
      "source": [
        "test_data['pred'] = labels\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>descA</th>\n",
              "      <th>descB</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>133</td>\n",
              "      <td>These clinical symptoms commonly occur in mult...</td>\n",
              "      <td>“BlackThorn is focused on developing a new gen...</td>\n",
              "      <td>1</td>\n",
              "      <td>LABEL_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2774</td>\n",
              "      <td>The innovation labs we have funded, have creat...</td>\n",
              "      <td>Approximately 60% of these jobs are held by Si...</td>\n",
              "      <td>0</td>\n",
              "      <td>LABEL_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3102</td>\n",
              "      <td>Mobile by design, Tabit is bringing the smartp...</td>\n",
              "      <td>At the 400 restaurants and cafes in Israel and...</td>\n",
              "      <td>0</td>\n",
              "      <td>LABEL_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>537</td>\n",
              "      <td>LeaseLock secured $10M in Series A financing f...</td>\n",
              "      <td>MARINA DEL REY, Calif., Aug 22, 2019 /PRNewswi...</td>\n",
              "      <td>1</td>\n",
              "      <td>LABEL_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1338</td>\n",
              "      <td>Same-day services, including order pickups and...</td>\n",
              "      <td>And offline store sales actually grew 10% at a...</td>\n",
              "      <td>0</td>\n",
              "      <td>LABEL_0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...     pred\n",
              "0         133  ...  LABEL_0\n",
              "1        2774  ...  LABEL_0\n",
              "2        3102  ...  LABEL_0\n",
              "3         537  ...  LABEL_1\n",
              "4        1338  ...  LABEL_0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "stream",
          "text": [
            "time: 29.7 ms (started: 2021-05-27 04:57:25 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "4IOCzATdvCTZ",
        "outputId": "d7179fcb-fe63-48ef-e059-0d6674886a07"
      },
      "source": [
        "label_dict = {'LABEL_0':0, 'LABEL_1':1}\n",
        "test_data['preds'] = test_data['pred'].map(label_dict)\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>descA</th>\n",
              "      <th>descB</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "      <th>preds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>133</td>\n",
              "      <td>These clinical symptoms commonly occur in mult...</td>\n",
              "      <td>“BlackThorn is focused on developing a new gen...</td>\n",
              "      <td>1</td>\n",
              "      <td>LABEL_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2774</td>\n",
              "      <td>The innovation labs we have funded, have creat...</td>\n",
              "      <td>Approximately 60% of these jobs are held by Si...</td>\n",
              "      <td>0</td>\n",
              "      <td>LABEL_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3102</td>\n",
              "      <td>Mobile by design, Tabit is bringing the smartp...</td>\n",
              "      <td>At the 400 restaurants and cafes in Israel and...</td>\n",
              "      <td>0</td>\n",
              "      <td>LABEL_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>537</td>\n",
              "      <td>LeaseLock secured $10M in Series A financing f...</td>\n",
              "      <td>MARINA DEL REY, Calif., Aug 22, 2019 /PRNewswi...</td>\n",
              "      <td>1</td>\n",
              "      <td>LABEL_1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1338</td>\n",
              "      <td>Same-day services, including order pickups and...</td>\n",
              "      <td>And offline store sales actually grew 10% at a...</td>\n",
              "      <td>0</td>\n",
              "      <td>LABEL_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... preds\n",
              "0         133  ...     0\n",
              "1        2774  ...     0\n",
              "2        3102  ...     0\n",
              "3         537  ...     1\n",
              "4        1338  ...     0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "stream",
          "text": [
            "time: 21 ms (started: 2021-05-27 04:57:28 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSzbZ22it5Eb",
        "outputId": "15180442-97f8-48ac-d2b3-489d416a347d"
      },
      "source": [
        "test_data.to_csv('data/predictions.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 230 ms (started: 2021-05-27 04:57:30 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9ek-idKB3J-",
        "outputId": "a047fa1b-dd31-4812-ed3b-6046b3f21bfa"
      },
      "source": [
        "actuals = test_data['label']\n",
        "preds = test_data['preds']\n",
        "print(classification_report(actuals, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.86       526\n",
            "           1       0.74      0.57      0.64       238\n",
            "\n",
            "    accuracy                           0.80       764\n",
            "   macro avg       0.78      0.74      0.75       764\n",
            "weighted avg       0.80      0.80      0.80       764\n",
            "\n",
            "time: 10.8 ms (started: 2021-05-27 04:57:32 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}