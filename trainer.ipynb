{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "trainer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP5qC03JzeAg",
        "outputId": "8492befe-3ad1-4994-e7e9-07f5fab00d06"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May 21 01:59:11 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WPQ203I0VxF",
        "outputId": "6caa0e30-ddbf-4dcb-8917-1f1f5f853f81"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYNe62YE0xo0",
        "outputId": "8d73b6f8-1ac7-4798-9f1a-874195618ddd"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/custom-EM-BERT/prof_entity"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/custom-EM-BERT/prof_entity\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mY8NnZrmaMx"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abtsyyse03Hr"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucz121h-zoYI"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
        "                             classification_report)\n",
        "\n",
        "# utils python file for custom data loading\n",
        "import utils\n",
        "from utils import load_data, create_sample\n",
        "\n",
        "# make use of the transformers library from hugging face\n",
        "# auto models and auto tokenizer allow for easy swap between models\n",
        "# supports various models like BERT, GPT, ....\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import TrainingArguments, Trainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cqZudMnm0HKM"
      },
      "source": [
        "# make use of colab's gpu\n",
        "use_gpu = True\n",
        "if use_gpu:\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "# for installing cuda-enabled torch version\n",
        "# pip uninstall torch\n",
        "# pip cache purge\n",
        "# pip install torch -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TVkYV5_12BQ"
      },
      "source": [
        "# DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA_Who_p08TD"
      },
      "source": [
        "# Load data\n",
        "df, is_entity, not_entity, signal_present = load_data(\n",
        "    data_fp='prof_entity/data',\n",
        "    file_path_or_ext='xlsx',\n",
        "    explore=False,\n",
        "    sheet_name='News Articles'\n",
        ")\n",
        "\n",
        "# Create positive and negative samples\n",
        "# samples are the the prior 3 sentences, and the current sentence\n",
        "# ['prior 3 sentences', 'current sentence']\n",
        "positive_samples = create_sample(df, is_entity, 3)\n",
        "negative_samples = create_sample(df, not_entity, 3)\n",
        "\n",
        "# ## Train-test split our data\n",
        "positive_labels = [1] * len(positive_samples)\n",
        "negative_labels = [0] * len(negative_samples)\n",
        "train_labels = positive_labels + negative_labels\n",
        "train_data = positive_samples + negative_samples\n",
        "assert len(train_data) == len(train_labels)\n",
        "\n",
        "train_seq, val_seq, train_labels, val_labels = train_test_split(\n",
        "    train_data, train_labels, shuffle=True, test_size=0.2\n",
        ")\n",
        "\n",
        "# choose the model to use here\n",
        "model_name = 'bert-base-uncased'\n",
        "\n",
        "# Create pre-trained model and tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZJ2Tdcym8bt",
        "outputId": "f541eaec-7201-47ee-b2c0-4582b6e16e88"
      },
      "source": [
        "print(positive_samples[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MeMe Live was founded in 2016 to enable users to watch live broadcasting anytime, anywhere and engage with the audience via live sessions The platform gives a chance to live stream the performances, broadcast what you are good at and let people enjoy based on the core values of integrity, innovation, pro-activeness and openness through a mobile broadcasting app Since its India launch, MeMe Live has been available on iOS as well as Android operating systems', 'It was later acquired by 17LIVE Group, the operator of Japan’s No.1 live-streaming platform, which claimed that the deal would consolidate the global live-streaming industry and expand into new markets upon the integration of the two companies’ platform resources, content creators, and users']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrTdUH3J6pqc",
        "outputId": "5c932118-3494-4456-9aef-3a21a15f4041"
      },
      "source": [
        "signal_present['entity (WIP)'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    2633\n",
              "1.0    1188\n",
              "Name: entity (WIP), dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNuj3Ijc5d-C",
        "outputId": "5f75ec4a-ee91-4f5c-df04-6f20f8a062f7"
      },
      "source": [
        "print(len(not_entity))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2BBe9Ew1H_2"
      },
      "source": [
        "# Use a dataloader to manage and optimize the data-in for training\n",
        "class EntityDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "# Encode data\n",
        "train_batch_first, train_batch_second = zip(*train_seq)\n",
        "train_encodings = tokenizer(\n",
        "    train_batch_first,\n",
        "    train_batch_second,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "val_batch_first, val_batch_second = zip(*val_seq)\n",
        "val_encodings = tokenizer(\n",
        "    val_batch_first,\n",
        "    val_batch_second,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "train_dataset = EntityDataset(train_encodings, train_labels)\n",
        "val_dataset = EntityDataset(val_encodings, val_labels)\n",
        "\n",
        "# ## Note: See Transformers datasets for instructions on how to local massive\n",
        "# datasets from local files."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47ZQslSUq6Ip",
        "outputId": "5af54d9d-c4b2-499a-afec-9bf970205d8d"
      },
      "source": [
        "print(train_batch_first[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "These insights enable providers to generate top-line revenue by identifying policies with potential for upsell or cross-sell, improve retention rates, reassign orphan policies, and optimize their books of business by generating real-time visibility of their risk portfolio Using Atidot, insurance executives are able to get a better understanding of current lapse rates and surrenders, reconfigure pricing and product bundling, and objectively and scientifically determine the accurate reserves and capital requirements for the company “We are honored to be included as one of the world’s most innovative insurtech companies and to be recognized by the industry for our solutions,” said Dror Katzav, CEO and Cofounder of Atidot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WLUjsJmrNQ6",
        "outputId": "f44942a7-d93b-4ace-d6c4-455cc468c1f6"
      },
      "source": [
        "print(train_batch_second[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "“We strive to make it easy for insurers to start generating insights, improve efficiency, and more effectively target existing and potential policyholders with new products and services - driving more revenue.”  Selected from over 1,000 companies by analysts and industry experts at FinTech Global, the finalists were recognized for their innovative use of technology to solve a significant industry problem, or to generate cost savings or efficiency improvements across the insurance value chain\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RcPS1ea2BML"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlbOCU1e2CDS"
      },
      "source": [
        "# Perform training\n",
        "# ## Additional metrics\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6grdwTtA2LZG"
      },
      "source": [
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='models/',\n",
        "    do_train=True,\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.001,\n",
        "    logging_dir='train/logs',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_loss',\n",
        "    # fp16=True,\n",
        "    # sharded_ddp='zero_dp_2'\n",
        ")\n",
        "\n",
        "# Set up trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "YZ6w3Abl2Pms",
        "outputId": "d79c206b-b5eb-4bb2-8f67-ce6838b339b8"
      },
      "source": [
        "# Train\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate trained model\n",
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3820' max='3820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3820/3820 1:40:47, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.519700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.313100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.141300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.055500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.015500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.008200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [48/48 00:50]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 10.0,\n",
              " 'eval_loss': 1.3649530410766602,\n",
              " 'eval_mem_cpu_alloc_delta': 0,\n",
              " 'eval_mem_cpu_peaked_delta': 0,\n",
              " 'eval_mem_gpu_alloc_delta': -87040,\n",
              " 'eval_mem_gpu_peaked_delta': 679710720,\n",
              " 'eval_runtime': 51.1988,\n",
              " 'eval_samples_per_second': 14.922}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAblRhnVRooj"
      },
      "source": [
        "trainer.save_model(output_dir='/content/gdrive/MyDrive/custom-EM-BERT/prof_entity/models')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-Tpi9zC2SjV"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "0syg3eZ_2Tbw",
        "outputId": "85d751e4-3f45-4388-fec9-e5b12ee2c1c4"
      },
      "source": [
        "# Check classification report\n",
        "predictions = trainer.predict(val_dataset)\n",
        "preds = np.argmax(predictions[0], axis=1)\n",
        "actuals = val_labels\n",
        "\n",
        "print(classification_report(actuals, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='96' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [48/48 01:43]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.89      0.89       551\n",
            "           1       0.72      0.73      0.73       213\n",
            "\n",
            "    accuracy                           0.85       764\n",
            "   macro avg       0.81      0.81      0.81       764\n",
            "weighted avg       0.85      0.85      0.85       764\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9DU2yJ24fbP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}